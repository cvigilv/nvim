import logging
import os

import mlflow
from mlflow.pyfunc.model import PythonModelContext

# from src import modules

MODEL_INPUT = {${cursor}}
MODEL_NAME = "toolbox::${lua:vim.fn.expand("%:p:h:t")}"


# Implement model pipeline class
class ModelPipeline(mlflow.pyfunc.PythonModel):
    """MODEL prediction pipeline to provide as a MLflow model"""

    def __init__(self, **kwargs):
        pass

    def load_context(self, context):
        pass

    def predict(self, context, model_inputs):
        """One-line description of pipeline

        Inputs
        ------
        model_inputs : dict
            Description of input dictionary, defining each key with its type with a
            small description

        Outputs
        -------
        model_outputs : dict
            Description of output dictionary, defining each key with its type with a
            small description

        Raises
        ------
        If model raises exceptions, describe them here

        Yields
        ------
        If model returns a generator, describe it here
        """
        pass


if __name__ == "__main__":
    # Configure MLflow experiment and location
    log = logging.getLogger(__name__)
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s | %(message)s"
    )

    model_stage_format = "models:/{task}/{stage}"
    model_version_format = "models:/{task}/{model_version}"

    usr = os.environ.get("MLFLOW_TRACKING_USERNAME")
    pwd = os.environ.get("MLFLOW_TRACKING_PASSWORD")

    mlflow.set_tracking_uri(f"https://{usr}:{pwd}@ml.madi.bio")
    mlflow.set_experiment(MODEL_NAME)

    # Test model pipeline class locally before logging model
    artifacts = {}
    context = PythonModelContext(artifacts)

    model_params = {}
    model = ModelPipeline(**model_params)
    model.load_context(context)

    model_output = model.predict(context, MODEL_INPUT)
    print(model_output)

    # Log model to MLflow registry
    with mlflow.start_run(run_name=MODEL_NAME) as mlflow_run:
        mlflow.pyfunc.log_model(
            artifact_path="model",
            artifacts=artifacts,
            pip_requirements="requirements_${lua:vim.fn.expand("%:p:h:t")}.txt",
            code_path=["./src"],
            python_model=ModelPipeline(**model_params),
            registered_model_name=MODEL_NAME,
        )
